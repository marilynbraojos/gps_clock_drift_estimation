{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13791a1f",
   "metadata": {},
   "source": [
    "# Gathering the Data: \n",
    "\n",
    "The first step is to collect the relevant data. We will be collecting information from the GPS navigation files for a week, and putting them on a CSV. We will be using GPS Week 1997, which corresponds to 4/15/2018 to 4/21/2018 (day 105 to day 111). If this proof of concept works, further automation for data retrieval needs to be done later ðŸš§. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6001ac0",
   "metadata": {},
   "source": [
    "RINEX Version: [Link to RINEX 3.02 PDF](https://files.igs.org/pub/data/format/rinex302.pdf)\n",
    "\n",
    "See A18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad0682",
   "metadata": {},
   "source": [
    "## Step 0A: Gather the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import chardet\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rnx_to_csv(year: str, day_of_year: str):\n",
    "    base_dir = os.path.dirname(__file__) if \"__file__\" in globals() else os.getcwd()\n",
    "    rnx_folder = os.path.join(base_dir, 'rnx', f'gps_rnx_daily_{year}{day_of_year}')\n",
    "    print(f\"{rnx_folder} exists.\")\n",
    "    \n",
    "    if not os.path.isdir(rnx_folder):\n",
    "        print(f\"Directory {rnx_folder} does not exist.\")\n",
    "        return\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for file_name in os.listdir(rnx_folder):\n",
    "        if not file_name.endswith(\".rnx\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(rnx_folder, file_name)\n",
    "\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                raw = f.read()\n",
    "                encoding = chardet.detect(raw)['encoding'] or 'utf-8'\n",
    "\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                first_line = f.readline()\n",
    "                is_version_3 = '3' in first_line[0:21]\n",
    "                if not is_version_3:\n",
    "                    print(f\"Skipping non-version 3 file: {file_name}\")\n",
    "                    continue\n",
    "\n",
    "                # Read to end of header\n",
    "                while 'END OF HEADER' not in f.readline():\n",
    "                    pass\n",
    "\n",
    "                while True:\n",
    "                    line = f.readline()\n",
    "                    if not line:\n",
    "                        break\n",
    "                    if not line.startswith('G'):\n",
    "                        continue\n",
    "\n",
    "                    subs_lines = [f.readline() for _ in range(6)]\n",
    "                    if not all(subs_lines):\n",
    "                        continue  # Skip incomplete entry\n",
    "\n",
    "                    try:\n",
    "                        entry = {\n",
    "                            'SV Name': line[0:3],\n",
    "                            'Epoch Year': int(line[3:8]),\n",
    "                            'Epoch Month': int(line[8:11]),\n",
    "                            'Epoch Day': int(line[11:14]),\n",
    "                            'Epoch Hour': int(line[14:17]),\n",
    "                            'Epoch Minute': int(line[17:20]),\n",
    "                            'Epoch Second': int(line[20:23]),\n",
    "                            'Clock Bias': float(line[23:42].lower().replace('d', 'e')),\n",
    "                            'Clock Drift': float(line[42:61].lower().replace('d', 'e')),\n",
    "                            'Clock Drift Rate': float(line[61:80].lower().replace('d', 'e')),\n",
    "\n",
    "                            'IODE': float(subs_lines[0][4:23].lower().replace('d', 'e')),\n",
    "                            'Crs': float(subs_lines[0][23:42].lower().replace('d', 'e')),\n",
    "                            'Delta n': float(subs_lines[0][42:61].lower().replace('d', 'e')),\n",
    "                            'M0': float(subs_lines[0][61:80].lower().replace('d', 'e')),\n",
    "\n",
    "                            'Cuc': float(subs_lines[1][4:23].lower().replace('d', 'e')),\n",
    "                            'Eccentricity': float(subs_lines[1][23:42].lower().replace('d', 'e')),\n",
    "                            'Cus': float(subs_lines[1][42:61].lower().replace('d', 'e')),\n",
    "                            'sqrtA': float(subs_lines[1][61:80].lower().replace('d', 'e')),\n",
    "\n",
    "                            'Toe': float(subs_lines[2][4:23].lower().replace('d', 'e')),\n",
    "                            'Cic': float(subs_lines[2][23:42].lower().replace('d', 'e')),\n",
    "                            'Omega0': float(subs_lines[2][42:61].lower().replace('d', 'e')),\n",
    "                            'Cis': float(subs_lines[2][61:80].lower().replace('d', 'e')),\n",
    "\n",
    "                            'Io': float(subs_lines[3][4:23].lower().replace('d', 'e')),\n",
    "                            'Crc': float(subs_lines[3][23:42].lower().replace('d', 'e')),\n",
    "                            'omega': float(subs_lines[3][42:61].lower().replace('d', 'e')),\n",
    "                            'OmegaDot': float(subs_lines[3][61:80].lower().replace('d', 'e')),\n",
    "\n",
    "                            'IDOT': float(subs_lines[4][4:23].lower().replace('d', 'e')),\n",
    "                            'Codes on L2': float(subs_lines[4][23:42].lower().replace('d', 'e')),\n",
    "                            'GPS Week': float(subs_lines[4][42:61].lower().replace('d', 'e')),\n",
    "                            'L2 P flag': float(subs_lines[4][61:80].lower().replace('d', 'e')),\n",
    "\n",
    "                            'SV Accuracy': float(subs_lines[5][4:23].lower().replace('d', 'e')),\n",
    "                            'SV Health': float(subs_lines[5][23:42].lower().replace('d', 'e')),\n",
    "                            'TGD': float(subs_lines[5][42:61].lower().replace('d', 'e')),\n",
    "                            'IODC': float(subs_lines[5][61:80].lower().replace('d', 'e')),\n",
    "                            'File': file_name\n",
    "                        }\n",
    "                        all_data.append(entry)\n",
    "\n",
    "                    except Exception as parse_err:\n",
    "                        print(f\"Parse error in {file_name}: {parse_err}\")\n",
    "                        continue\n",
    "\n",
    "        except Exception as read_err:\n",
    "            print(f\"Error reading {file_name}: {read_err}\")\n",
    "\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        output_csv = os.path.join(base_dir, f'gps_rnx_{year}{day_of_year}.csv')\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"Saved {df.shape} entries to {output_csv}\")\n",
    "    else:\n",
    "        print(f\"No data parsed for day {day_of_year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example run\n",
    "for day in range(103, 114):  # days 103 to 113\n",
    "    process_rnx_to_csv(\"2018\", f\"{day:03d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_clk_to_csv(week: int):\n",
    "    base_dir = os.path.dirname(__file__) if \"__file__\" in globals() else os.getcwd()\n",
    "    clk_folder = os.path.join(base_dir, \"clk\", f\"gps_{week}\")\n",
    "\n",
    "    if not os.path.isdir(clk_folder):\n",
    "        print(f\"Directory {clk_folder} does not exist.\")\n",
    "        return\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for file_name in os.listdir(clk_folder):\n",
    "        if not file_name.lower().endswith(\".clk\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(clk_folder, file_name)\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"r\") as f:\n",
    "                first_line = f.readline()\n",
    "                second_line = f.readline()\n",
    "                is_version_3 = \"3.04\" in first_line[0:21]\n",
    "                end_header = False\n",
    "\n",
    "                for line in f:\n",
    "                    if not end_header:\n",
    "                        if \"END OF HEADER\" in line:\n",
    "                            end_header = True\n",
    "                        continue\n",
    "\n",
    "                    if not line.startswith(\"AS\"):\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        # Version 3\n",
    "                        if is_version_3 and \"CNES\" in second_line[21:42].upper() and line[3:13].startswith(\"G\"):\n",
    "                            row = {\n",
    "                                \"Clock Data Type\": line[0:3],\n",
    "                                \"SV Name\": line[3:13].strip(),\n",
    "                                \"Epoch Year\": int(line[13:18]),\n",
    "                                \"Epoch Month\": int(line[18:21]),\n",
    "                                \"Epoch Day\": int(line[21:24]),\n",
    "                                \"Epoch Hour\": int(line[24:27]),\n",
    "                                \"Epoch Minute\": int(line[27:30]),\n",
    "                                \"Epoch Second\": int(float(line[30:40])),\n",
    "                                \"Clock Bias (seconds)\": float(line[45:66].lower().replace(\"d\", \"e\")),\n",
    "                                \"Version\": \"3.04\",\n",
    "                                \"File\": file_name\n",
    "                            }\n",
    "                            all_data.append(row)\n",
    "\n",
    "                        # Pre-3\n",
    "                        elif not is_version_3 and \"CNES\" in second_line[20:40].upper() and line[3:8].startswith(\"G\"):\n",
    "                            row = {\n",
    "                                \"Clock Data Type\": line[0:3],\n",
    "                                \"SV Name\": line[3:8].strip(),\n",
    "                                \"Epoch Year\": int(line[8:12]),\n",
    "                                \"Epoch Month\": int(line[12:15]),\n",
    "                                \"Epoch Day\": int(line[15:18]),\n",
    "                                \"Epoch Hour\": int(line[18:21]),\n",
    "                                \"Epoch Minute\": int(line[21:24]),\n",
    "                                \"Epoch Second\": int(float(line[24:34])),\n",
    "                                \"Clock Bias (seconds)\": float(line[40:59].lower().replace(\"d\", \"e\")),\n",
    "                                \"Version\": \"Pre-3.04\",\n",
    "                                \"File\": file_name\n",
    "                            }\n",
    "                            all_data.append(row)\n",
    "\n",
    "                    except Exception as parse_err:\n",
    "                        print(f\"Parse error in {file_name}: {parse_err}\")\n",
    "                        continue\n",
    "\n",
    "        except Exception as read_err:\n",
    "            print(f\"Error reading {file_name}: {read_err}\")\n",
    "\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        df.sort_values(by=[\"Epoch Year\", \"Epoch Month\", \"Epoch Day\", \"Epoch Hour\", \"Epoch Minute\", \"Epoch Second\"], inplace=True)\n",
    "        output_csv = os.path.join(base_dir, f\"gps_clk_week_{week}.csv\")\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"Saved {len(df)} entries to {output_csv}\")\n",
    "    else:\n",
    "        print(f\"No valid data found for GPS week {week}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6221818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example call\n",
    "for week in range(1997, 1998):  # Just week 1997 for now\n",
    "    process_clk_to_csv(week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdbc339",
   "metadata": {},
   "source": [
    "## Step 0B: Consolidate all RINEX files into single RNX info file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "folder_path = \".\"  # current folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"gps_rnx_*.csv\")) # glob is a python module to search for file path names that match a specific pattern\n",
    "combined_df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "combined_df.to_csv(\"rnx_1997_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfb6fc3",
   "metadata": {},
   "source": [
    "## Step 0C: Fix SV Naming Issue with RNX files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fd1215",
   "metadata": {},
   "source": [
    "The RNX files have the SV names listed as G 1 vs the CLK files have them listed as G01. Let's ensure that they're named using the same format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "rnx_df = pd.read_csv(\"rnx_1997_raw.csv\")\n",
    "rnx_df['SV Name'] = rnx_df['SV Name'].str.replace(r'^G (\\d)$', r'G0\\1', regex=True)\n",
    "rnx_df.to_csv(\"rnx_1997_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb8d184",
   "metadata": {},
   "source": [
    "## Step 1: Match up and add CLK bias from IGS to RNX file yield a comined dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a0c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "rnx_df = pd.read_csv(\"rnx_1997_raw.csv\")\n",
    "clk_df = pd.read_csv(\"gps_clk_week_1997.csv\")\n",
    "\n",
    "merge_cols = [\"SV Name\", \"Epoch Year\", \"Epoch Month\", \"Epoch Day\", \"Epoch Hour\", \"Epoch Minute\", \"Epoch Second\"]\n",
    "\n",
    "merged_df = pd.merge(rnx_df, \n",
    "                    clk_df[merge_cols + [\"Clock Bias (seconds)\"]], \n",
    "                    on = merge_cols, \n",
    "                    how = \"left\")\n",
    "\n",
    "merged_df.to_csv(\"1_combined_raw_dataset.csv\", index = False)\n",
    "\n",
    "print(f\"Merged file saved with shape: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ccb02",
   "metadata": {},
   "source": [
    "## Step 2: Drop Rows without a CLK bias (seconds) or with missing data entries - we want a complete dataset without gaps in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62491ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv(\"1_combined_raw_dataset.csv\")\n",
    "\n",
    "complete_df = combined_df.dropna() # drop rows w at least 1 NaN\n",
    "\n",
    "complete_df.to_csv(\"2_complete_raw_dataset.csv\", index = False)\n",
    "\n",
    "print(f\"Saved cleaned complete dataset and went from {combined_df.shape} to {complete_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd84fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_cols = ['Epoch Hour', 'Epoch Minute', 'Epoch Second']\n",
    "\n",
    "# Check if any value is not zero in each column\n",
    "for col in epoch_cols:\n",
    "    non_zero = complete_df[complete_df[col] != 0]\n",
    "    if not non_zero.empty:\n",
    "        print(f\"Non-zero values found in '{col}':\")\n",
    "        print(non_zero[[col]])\n",
    "    else:\n",
    "        print(f\"All values in '{col}' are zero.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f156ada4",
   "metadata": {},
   "source": [
    "All 'seconds' columns are 0, but for every minute, hour, day, month and year there are values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3da94b",
   "metadata": {},
   "source": [
    "## Step 3: Adding a datetime object column to track sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8677db",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.read_csv(\"2_complete_raw_dataset.csv\")\n",
    "\n",
    "# create datetime col\n",
    "complete_df[\"epoch\"] = pd.to_datetime({\n",
    "    \"year\": complete_df[\"Epoch Year\"],\n",
    "    \"month\": complete_df[\"Epoch Month\"],\n",
    "    \"day\": complete_df[\"Epoch Day\"],\n",
    "    \"hour\": complete_df[\"Epoch Hour\"],\n",
    "    \"minute\": complete_df[\"Epoch Minute\"],\n",
    "    \"second\": complete_df[\"Epoch Second\"]\n",
    "})\n",
    "\n",
    "complete_df.to_csv(\"3_create_datetime_objects.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37c4566",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e80ca",
   "metadata": {},
   "source": [
    "## Step 3A: Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00387705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "complete_df = pd.read_csv(\"3_create_datetime_objects.csv\")\n",
    "\n",
    "# Group by 'SV Name'\n",
    "grouped = complete_df.groupby('SV Name')\n",
    "\n",
    "# Create one plot per SV Name\n",
    "for sv_name, group in grouped:\n",
    "    # Sort by epoch to ensure proper plotting\n",
    "    group = group.sort_values('epoch')\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Line plot for continuity\n",
    "    plt.plot(group['epoch'], group['Clock Bias (seconds)'], label='Line Plot')\n",
    "    \n",
    "    # Scatter plot for actual data points\n",
    "    plt.scatter(group['epoch'], group['Clock Bias (seconds)'], color='red', s=10, label='Data Points')\n",
    "    \n",
    "    plt.title(f'Clock Bias Over Time - {sv_name}')\n",
    "    plt.xlabel('Datetime')\n",
    "    plt.ylabel('Clock Bias (seconds)')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0733f5c",
   "metadata": {},
   "source": [
    "## Step 4: Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8173b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df = pd.read_csv(\"3_create_datetime_objects.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3190aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df['epoch'] = pd.to_datetime(datetime_df['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    'Unnamed: 0.1', 'Unnamed: 0',\n",
    "    'Epoch Year', 'Epoch Month', 'Epoch Day',\n",
    "    'Epoch Hour', 'Epoch Minute', 'Epoch Second'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84fbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df = datetime_df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda56619",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = datetime_df[datetime_df.duplicated(subset=['SV Name', 'epoch'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1225f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = duplicates[duplicates['SV Health'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = datetime_df.drop(index=to_delete.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4653d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "still_duplicated = cleaned_df.duplicated(subset=['SV Name', 'epoch'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0728fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = cleaned_df[~still_duplicated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df437ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete.to_csv(\"deleted_rows_due_to_sv_health.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb4a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.set_index('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa40ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('4_remove_unnecessary_cols_and_repeats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934cd8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3fc35",
   "metadata": {},
   "source": [
    "## Step 5: Make dataset a regular time series by interpolating missing values per SV group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56309b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_df = pd.read_csv(\"4_remove_unnecessary_cols_and_repeats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e479aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_df['SV Name'] = pruned_df['SV Name'].str.replace('G', '', regex=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f647db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_df['epoch'] = pd.to_datetime(pruned_df['epoch'])\n",
    "pruned_df = pruned_df.set_index('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451656f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_df = pruned_df.sort_values(['SV Name', 'epoch'])\n",
    "pruned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb34961",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df = (\n",
    "    pruned_df\n",
    "    .groupby('SV Name')\n",
    "    .resample('1T')  # 1-minute frequency\n",
    "    .asfreq()\n",
    "    .interpolate(method='linear', limit_area='inside')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e497a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4878d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df.to_csv(\"5_resampled_1min_interval.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e25f4",
   "metadata": {},
   "source": [
    "## Step 6: Normalize Continuous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df = pd.read_csv(\"5_resampled_1min_interval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6649e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fdc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd914f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = resampled_df.columns.difference(['epoch', 'SV Name', 'File'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac28dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952fb3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df[cols_to_scale] = scaler.fit_transform(resampled_df[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resampled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df.to_csv(\"6_scaled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c66f3",
   "metadata": {},
   "source": [
    "## Step 7: Normalizing Time Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60cb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.read_csv(\"6_scaled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7deace8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using raw dataset without scaling \n",
    "import pandas as pd\n",
    "scaled_df = pd.read_csv(\"5_resampled_1min_interval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1f8369d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SV Name</th>\n",
       "      <th>epoch</th>\n",
       "      <th>SV Name.1</th>\n",
       "      <th>Clock Bias</th>\n",
       "      <th>Clock Drift</th>\n",
       "      <th>Clock Drift Rate</th>\n",
       "      <th>IODE</th>\n",
       "      <th>Crs</th>\n",
       "      <th>Delta n</th>\n",
       "      <th>M0</th>\n",
       "      <th>...</th>\n",
       "      <th>IDOT</th>\n",
       "      <th>Codes on L2</th>\n",
       "      <th>GPS Week</th>\n",
       "      <th>L2 P flag</th>\n",
       "      <th>SV Accuracy</th>\n",
       "      <th>SV Health</th>\n",
       "      <th>TGD</th>\n",
       "      <th>IODC</th>\n",
       "      <th>File</th>\n",
       "      <th>Clock Bias (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-15 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-2.614797e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>42.562500</td>\n",
       "      <td>4.851274e-09</td>\n",
       "      <td>1.327367</td>\n",
       "      <td>...</td>\n",
       "      <td>1.678641e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.587935e-09</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>KITG00UZB_R_20181040000_01D_GN.rnx</td>\n",
       "      <td>-0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-15 00:01:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-2.614797e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.083333</td>\n",
       "      <td>42.645573</td>\n",
       "      <td>4.851029e-09</td>\n",
       "      <td>1.336121</td>\n",
       "      <td>...</td>\n",
       "      <td>1.692809e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.587935e-09</td>\n",
       "      <td>89.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-15 00:02:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-2.614797e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.166667</td>\n",
       "      <td>42.728646</td>\n",
       "      <td>4.850785e-09</td>\n",
       "      <td>1.344874</td>\n",
       "      <td>...</td>\n",
       "      <td>1.706976e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.587935e-09</td>\n",
       "      <td>89.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-15 00:03:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-2.614797e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.250000</td>\n",
       "      <td>42.811719</td>\n",
       "      <td>4.850541e-09</td>\n",
       "      <td>1.353627</td>\n",
       "      <td>...</td>\n",
       "      <td>1.721143e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.587935e-09</td>\n",
       "      <td>89.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-15 00:04:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-2.614797e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.333333</td>\n",
       "      <td>42.894792</td>\n",
       "      <td>4.850297e-09</td>\n",
       "      <td>1.362380</td>\n",
       "      <td>...</td>\n",
       "      <td>1.735310e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.587935e-09</td>\n",
       "      <td>89.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308186</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-04-21 21:56:00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>3.979039e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.933333</td>\n",
       "      <td>5.603125</td>\n",
       "      <td>4.653539e-09</td>\n",
       "      <td>-2.668432</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017304e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.656613e-10</td>\n",
       "      <td>81.933333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308187</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-04-21 21:57:00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>3.979039e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.950000</td>\n",
       "      <td>5.608594</td>\n",
       "      <td>4.652971e-09</td>\n",
       "      <td>-2.712040</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017453e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.656613e-10</td>\n",
       "      <td>81.950000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308188</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-04-21 21:58:00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>3.979039e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.966667</td>\n",
       "      <td>5.614063</td>\n",
       "      <td>4.652402e-09</td>\n",
       "      <td>-2.755649</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017602e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.656613e-10</td>\n",
       "      <td>81.966667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308189</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-04-21 21:59:00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>3.979039e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.983333</td>\n",
       "      <td>5.619531</td>\n",
       "      <td>4.651834e-09</td>\n",
       "      <td>-2.799257</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017751e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.656613e-10</td>\n",
       "      <td>81.983333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308190</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-04-21 22:00:00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>3.979039e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>4.651265e-09</td>\n",
       "      <td>-2.842865</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017900e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.656613e-10</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>BRUX00BEL_R_20181120000_01D_GN.rnx</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308191 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SV Name                epoch  SV Name.1  Clock Bias   Clock Drift  \\\n",
       "0             1  2018-04-15 00:00:00        1.0   -0.000041 -2.614797e-12   \n",
       "1             1  2018-04-15 00:01:00        1.0   -0.000041 -2.614797e-12   \n",
       "2             1  2018-04-15 00:02:00        1.0   -0.000041 -2.614797e-12   \n",
       "3             1  2018-04-15 00:03:00        1.0   -0.000041 -2.614797e-12   \n",
       "4             1  2018-04-15 00:04:00        1.0   -0.000041 -2.614797e-12   \n",
       "...         ...                  ...        ...         ...           ...   \n",
       "308186       32  2018-04-21 21:56:00       32.0   -0.000518  3.979039e-12   \n",
       "308187       32  2018-04-21 21:57:00       32.0   -0.000518  3.979039e-12   \n",
       "308188       32  2018-04-21 21:58:00       32.0   -0.000518  3.979039e-12   \n",
       "308189       32  2018-04-21 21:59:00       32.0   -0.000518  3.979039e-12   \n",
       "308190       32  2018-04-21 22:00:00       32.0   -0.000518  3.979039e-12   \n",
       "\n",
       "        Clock Drift Rate       IODE        Crs       Delta n        M0  ...  \\\n",
       "0                    0.0  89.000000  42.562500  4.851274e-09  1.327367  ...   \n",
       "1                    0.0  89.083333  42.645573  4.851029e-09  1.336121  ...   \n",
       "2                    0.0  89.166667  42.728646  4.850785e-09  1.344874  ...   \n",
       "3                    0.0  89.250000  42.811719  4.850541e-09  1.353627  ...   \n",
       "4                    0.0  89.333333  42.894792  4.850297e-09  1.362380  ...   \n",
       "...                  ...        ...        ...           ...       ...  ...   \n",
       "308186               0.0  81.933333   5.603125  4.653539e-09 -2.668432  ...   \n",
       "308187               0.0  81.950000   5.608594  4.652971e-09 -2.712040  ...   \n",
       "308188               0.0  81.966667   5.614063  4.652402e-09 -2.755649  ...   \n",
       "308189               0.0  81.983333   5.619531  4.651834e-09 -2.799257  ...   \n",
       "308190               0.0  82.000000   5.625000  4.651265e-09 -2.842865  ...   \n",
       "\n",
       "                IDOT  Codes on L2  GPS Week  L2 P flag  SV Accuracy  \\\n",
       "0       1.678641e-10          1.0    1997.0        0.0        3.400   \n",
       "1       1.692809e-10          1.0    1997.0        0.0        3.395   \n",
       "2       1.706976e-10          1.0    1997.0        0.0        3.390   \n",
       "3       1.721143e-10          1.0    1997.0        0.0        3.385   \n",
       "4       1.735310e-10          1.0    1997.0        0.0        3.380   \n",
       "...              ...          ...       ...        ...          ...   \n",
       "308186 -1.017304e-10          1.0    1997.0        0.0        2.000   \n",
       "308187 -1.017453e-10          1.0    1997.0        0.0        2.000   \n",
       "308188 -1.017602e-10          1.0    1997.0        0.0        2.000   \n",
       "308189 -1.017751e-10          1.0    1997.0        0.0        2.000   \n",
       "308190 -1.017900e-10          1.0    1997.0        0.0        2.000   \n",
       "\n",
       "        SV Health           TGD       IODC  \\\n",
       "0             0.0  5.587935e-09  89.000000   \n",
       "1             0.0  5.587935e-09  89.083333   \n",
       "2             0.0  5.587935e-09  89.166667   \n",
       "3             0.0  5.587935e-09  89.250000   \n",
       "4             0.0  5.587935e-09  89.333333   \n",
       "...           ...           ...        ...   \n",
       "308186        0.0  4.656613e-10  81.933333   \n",
       "308187        0.0  4.656613e-10  81.950000   \n",
       "308188        0.0  4.656613e-10  81.966667   \n",
       "308189        0.0  4.656613e-10  81.983333   \n",
       "308190        0.0  4.656613e-10  82.000000   \n",
       "\n",
       "                                      File  Clock Bias (seconds)  \n",
       "0       KITG00UZB_R_20181040000_01D_GN.rnx             -0.000041  \n",
       "1                                      NaN             -0.000041  \n",
       "2                                      NaN             -0.000041  \n",
       "3                                      NaN             -0.000041  \n",
       "4                                      NaN             -0.000041  \n",
       "...                                    ...                   ...  \n",
       "308186                                 NaN             -0.000518  \n",
       "308187                                 NaN             -0.000518  \n",
       "308188                                 NaN             -0.000518  \n",
       "308189                                 NaN             -0.000518  \n",
       "308190  BRUX00BEL_R_20181120000_01D_GN.rnx             -0.000518  \n",
       "\n",
       "[308191 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix datetime column\n",
    "scaled_df[\"epoch\"] = pd.to_datetime(scaled_df[\"epoch\"])\n",
    "\n",
    "# Create time index in units of 30-second intervals since global start\n",
    "scaled_df[\"time_idx\"] = ((scaled_df[\"epoch\"] - scaled_df[\"epoch\"].min()).dt.total_seconds() / 60).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e159ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.to_csv(\"7_time_idx_added.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f66696",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753c4d6",
   "metadata": {},
   "source": [
    "## Delete Weird Rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94911f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SV Name</th>\n",
       "      <th>epoch</th>\n",
       "      <th>SV Name.1</th>\n",
       "      <th>Clock Bias</th>\n",
       "      <th>Clock Drift</th>\n",
       "      <th>Clock Drift Rate</th>\n",
       "      <th>IODE</th>\n",
       "      <th>Crs</th>\n",
       "      <th>Delta n</th>\n",
       "      <th>M0</th>\n",
       "      <th>...</th>\n",
       "      <th>IDOT</th>\n",
       "      <th>Codes on L2</th>\n",
       "      <th>GPS Week</th>\n",
       "      <th>L2 P flag</th>\n",
       "      <th>SV Accuracy</th>\n",
       "      <th>SV Health</th>\n",
       "      <th>TGD</th>\n",
       "      <th>IODC</th>\n",
       "      <th>File</th>\n",
       "      <th>Clock Bias (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-15 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-2.614797e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>42.562500</td>\n",
       "      <td>4.851274e-09</td>\n",
       "      <td>1.327367</td>\n",
       "      <td>...</td>\n",
       "      <td>1.678641e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.587935e-09</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>KITG00UZB_R_20181040000_01D_GN.rnx</td>\n",
       "      <td>-0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-15 00:01:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-2.614797e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.083333</td>\n",
       "      <td>42.645573</td>\n",
       "      <td>4.851029e-09</td>\n",
       "      <td>1.336121</td>\n",
       "      <td>...</td>\n",
       "      <td>1.692809e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.587935e-09</td>\n",
       "      <td>89.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-15 00:02:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-2.614797e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.166667</td>\n",
       "      <td>42.728646</td>\n",
       "      <td>4.850785e-09</td>\n",
       "      <td>1.344874</td>\n",
       "      <td>...</td>\n",
       "      <td>1.706976e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.587935e-09</td>\n",
       "      <td>89.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-15 00:03:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-2.614797e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.250000</td>\n",
       "      <td>42.811719</td>\n",
       "      <td>4.850541e-09</td>\n",
       "      <td>1.353627</td>\n",
       "      <td>...</td>\n",
       "      <td>1.721143e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.587935e-09</td>\n",
       "      <td>89.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-15 00:04:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-2.614797e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.333333</td>\n",
       "      <td>42.894792</td>\n",
       "      <td>4.850297e-09</td>\n",
       "      <td>1.362380</td>\n",
       "      <td>...</td>\n",
       "      <td>1.735310e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.587935e-09</td>\n",
       "      <td>89.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308186</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-04-21 21:56:00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>3.979039e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.933333</td>\n",
       "      <td>5.603125</td>\n",
       "      <td>4.653539e-09</td>\n",
       "      <td>-2.668432</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017304e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.656613e-10</td>\n",
       "      <td>81.933333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308187</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-04-21 21:57:00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>3.979039e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.950000</td>\n",
       "      <td>5.608594</td>\n",
       "      <td>4.652971e-09</td>\n",
       "      <td>-2.712040</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017453e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.656613e-10</td>\n",
       "      <td>81.950000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308188</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-04-21 21:58:00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>3.979039e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.966667</td>\n",
       "      <td>5.614063</td>\n",
       "      <td>4.652402e-09</td>\n",
       "      <td>-2.755649</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017602e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.656613e-10</td>\n",
       "      <td>81.966667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308189</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-04-21 21:59:00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>3.979039e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.983333</td>\n",
       "      <td>5.619531</td>\n",
       "      <td>4.651834e-09</td>\n",
       "      <td>-2.799257</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017751e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.656613e-10</td>\n",
       "      <td>81.983333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308190</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-04-21 22:00:00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>3.979039e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>4.651265e-09</td>\n",
       "      <td>-2.842865</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017900e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.656613e-10</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>BRUX00BEL_R_20181120000_01D_GN.rnx</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308191 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SV Name                epoch  SV Name.1  Clock Bias   Clock Drift  \\\n",
       "0             1  2018-04-15 00:00:00        1.0   -0.000041 -2.614797e-12   \n",
       "1             1  2018-04-15 00:01:00        1.0   -0.000041 -2.614797e-12   \n",
       "2             1  2018-04-15 00:02:00        1.0   -0.000041 -2.614797e-12   \n",
       "3             1  2018-04-15 00:03:00        1.0   -0.000041 -2.614797e-12   \n",
       "4             1  2018-04-15 00:04:00        1.0   -0.000041 -2.614797e-12   \n",
       "...         ...                  ...        ...         ...           ...   \n",
       "308186       32  2018-04-21 21:56:00       32.0   -0.000518  3.979039e-12   \n",
       "308187       32  2018-04-21 21:57:00       32.0   -0.000518  3.979039e-12   \n",
       "308188       32  2018-04-21 21:58:00       32.0   -0.000518  3.979039e-12   \n",
       "308189       32  2018-04-21 21:59:00       32.0   -0.000518  3.979039e-12   \n",
       "308190       32  2018-04-21 22:00:00       32.0   -0.000518  3.979039e-12   \n",
       "\n",
       "        Clock Drift Rate       IODE        Crs       Delta n        M0  ...  \\\n",
       "0                    0.0  89.000000  42.562500  4.851274e-09  1.327367  ...   \n",
       "1                    0.0  89.083333  42.645573  4.851029e-09  1.336121  ...   \n",
       "2                    0.0  89.166667  42.728646  4.850785e-09  1.344874  ...   \n",
       "3                    0.0  89.250000  42.811719  4.850541e-09  1.353627  ...   \n",
       "4                    0.0  89.333333  42.894792  4.850297e-09  1.362380  ...   \n",
       "...                  ...        ...        ...           ...       ...  ...   \n",
       "308186               0.0  81.933333   5.603125  4.653539e-09 -2.668432  ...   \n",
       "308187               0.0  81.950000   5.608594  4.652971e-09 -2.712040  ...   \n",
       "308188               0.0  81.966667   5.614063  4.652402e-09 -2.755649  ...   \n",
       "308189               0.0  81.983333   5.619531  4.651834e-09 -2.799257  ...   \n",
       "308190               0.0  82.000000   5.625000  4.651265e-09 -2.842865  ...   \n",
       "\n",
       "                IDOT  Codes on L2  GPS Week  L2 P flag  SV Accuracy  \\\n",
       "0       1.678641e-10          1.0    1997.0        0.0        3.400   \n",
       "1       1.692809e-10          1.0    1997.0        0.0        3.395   \n",
       "2       1.706976e-10          1.0    1997.0        0.0        3.390   \n",
       "3       1.721143e-10          1.0    1997.0        0.0        3.385   \n",
       "4       1.735310e-10          1.0    1997.0        0.0        3.380   \n",
       "...              ...          ...       ...        ...          ...   \n",
       "308186 -1.017304e-10          1.0    1997.0        0.0        2.000   \n",
       "308187 -1.017453e-10          1.0    1997.0        0.0        2.000   \n",
       "308188 -1.017602e-10          1.0    1997.0        0.0        2.000   \n",
       "308189 -1.017751e-10          1.0    1997.0        0.0        2.000   \n",
       "308190 -1.017900e-10          1.0    1997.0        0.0        2.000   \n",
       "\n",
       "        SV Health           TGD       IODC  \\\n",
       "0             0.0  5.587935e-09  89.000000   \n",
       "1             0.0  5.587935e-09  89.083333   \n",
       "2             0.0  5.587935e-09  89.166667   \n",
       "3             0.0  5.587935e-09  89.250000   \n",
       "4             0.0  5.587935e-09  89.333333   \n",
       "...           ...           ...        ...   \n",
       "308186        0.0  4.656613e-10  81.933333   \n",
       "308187        0.0  4.656613e-10  81.950000   \n",
       "308188        0.0  4.656613e-10  81.966667   \n",
       "308189        0.0  4.656613e-10  81.983333   \n",
       "308190        0.0  4.656613e-10  82.000000   \n",
       "\n",
       "                                      File  Clock Bias (seconds)  \n",
       "0       KITG00UZB_R_20181040000_01D_GN.rnx             -0.000041  \n",
       "1                                      NaN             -0.000041  \n",
       "2                                      NaN             -0.000041  \n",
       "3                                      NaN             -0.000041  \n",
       "4                                      NaN             -0.000041  \n",
       "...                                    ...                   ...  \n",
       "308186                                 NaN             -0.000518  \n",
       "308187                                 NaN             -0.000518  \n",
       "308188                                 NaN             -0.000518  \n",
       "308189                                 NaN             -0.000518  \n",
       "308190  BRUX00BEL_R_20181120000_01D_GN.rnx             -0.000518  \n",
       "\n",
       "[308191 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  using unscaled dataset \n",
    "import pandas as pd\n",
    "weird_rows_delete = pd.read_csv(\"5_resampled_1min_interval.csv\")\n",
    "weird_rows_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c7985",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_rows_delete = pd.read_csv(\"7_time_idx_added.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47119ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_rows_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff63b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using unscaled dataset \n",
    "cols_to_drop = ['Unnamed: 0.1', 'Unnamed: 0', 'SV Name.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9029fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Unnamed: 0.1', 'Unnamed: 0', 'SV Name.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1609604",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_rows_delete = weird_rows_delete.drop(columns=cols_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08720d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_rows_delete.to_csv(\"8_no_bad_rows.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e81668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268210fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a0c1533",
   "metadata": {},
   "source": [
    "## EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.read_csv(\"6_scaled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121fcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649cf3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de98ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sorted unique IODE values\n",
    "unique_iode_sorted = sorted(df[\"IODE\"].dropna().unique())  # dropna in case of any missing values\n",
    "\n",
    "# Build a mapping like {12: 1, 18: 2, 29: 3, ...}\n",
    "iode_mapping = {val: i + 1 for i, val in enumerate(unique_iode_sorted)}\n",
    "\n",
    "# Apply the mapping\n",
    "df[\"IODE Encoded\"] = df[\"IODE\"].map(iode_mapping)\n",
    "\n",
    "# Preview mapping\n",
    "print(\"IODE â†’ Encoded Value (sorted):\")\n",
    "for val in list(iode_mapping)[:1000]:\n",
    "    print(f\"{val} â†’ {iode_mapping[val]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sorted unique Codes on L2 values\n",
    "unique_l2_codes_sorted = sorted(df[\"Codes on L2\"].dropna().unique())\n",
    "\n",
    "# Build mapping like {1: 1, 2: 2, 5: 3, ...}\n",
    "l2_code_mapping = {val: i + 1 for i, val in enumerate(unique_l2_codes_sorted)}\n",
    "\n",
    "# Apply the mapping\n",
    "df[\"Codes on L2 Encoded\"] = df[\"Codes on L2\"].map(l2_code_mapping)\n",
    "\n",
    "# Preview mapping\n",
    "print(\"Codes on L2 â†’ Encoded Value (sorted):\")\n",
    "for val in list(l2_code_mapping)[:10]:\n",
    "    print(f\"{val} â†’ {l2_code_mapping[val]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe113ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sorted unique SV Health values\n",
    "unique_sv_health_sorted = sorted(df[\"SV Health\"].dropna().unique())\n",
    "\n",
    "# Build mapping like {0: 1, 1: 2, 2: 3, ...}\n",
    "sv_health_mapping = {val: i + 1 for i, val in enumerate(unique_sv_health_sorted)}\n",
    "\n",
    "# Apply the mapping\n",
    "df[\"SV Health Encoded\"] = df[\"SV Health\"].map(sv_health_mapping)\n",
    "\n",
    "# Preview mapping\n",
    "print(\"SV Health â†’ Encoded Value (sorted):\")\n",
    "for val in list(sv_health_mapping)[:10]:\n",
    "    print(f\"{val} â†’ {sv_health_mapping[val]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sorted unique IODC values\n",
    "unique_iodc_sorted = sorted(df[\"IODC\"].dropna().unique())\n",
    "\n",
    "# Build mapping like {1: 1, 5: 2, 6: 3, ...}\n",
    "iodc_mapping = {val: i + 1 for i, val in enumerate(unique_iodc_sorted)}\n",
    "\n",
    "# Apply the mapping\n",
    "df[\"IODC Encoded\"] = df[\"IODC\"].map(iodc_mapping)\n",
    "\n",
    "# Preview mapping\n",
    "print(\"IODC â†’ Encoded Value (sorted):\")\n",
    "for val in list(iodc_mapping)[:1000]:\n",
    "    print(f\"{val} â†’ {iodc_mapping[val]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3115ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows where Epoch Minute == 0\n",
    "df = df[df[\"Epoch Minute\"] == 0]\n",
    "\n",
    "# Reset index if needed\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Confirm it's working\n",
    "print(\"Unique values in 'Epoch Minute':\", df[\"Epoch Minute\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989277fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_counts = df[\"SV Name\"].value_counts()\n",
    "\n",
    "print(\"Number of data points per SV Name:\")\n",
    "print(sv_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ebcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define your continuous columns\n",
    "continuous_cols = [col for col in df.columns \n",
    "                   if col not in [\"epoch\", \"SV Name\", \"IODE\", \"Codes on L2\", \n",
    "                                  \"SV Health\", \"IODC\", \n",
    "                                  \"Epoch Year\", \"Epoch Month\", \"Epoch Day\", \n",
    "                                  \"Epoch Hour\", \"Epoch Minute\", \"Epoch Second\", \"File\"]]\n",
    "\n",
    "# Apply Min-Max scaling to each column independently\n",
    "for col in continuous_cols:\n",
    "    scaler = MinMaxScaler()\n",
    "    df[col] = scaler.fit_transform(df[[col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7935f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"complete_dataset_scaled.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28fd910",
   "metadata": {},
   "source": [
    "# Notes: \n",
    "\n",
    "The previous part of this project investigated whether broadcast clock bias could be used to forecast a correction that would yield a more accurate clock bias correction. This was investigated by leveraging the IGS post-processed products as the ground truth clock bias, then the difference from it and the broadcast clock bias was evaluated and this value was used as the model's label. The previous model was an encoder only transformer, the subsequent model was a Temporal Fusion Transformer (specifically designed to forecast multi-variate time series). While both models achieved low RMSE metrics, their R2 values did not correlate with a model of optimal performance (i.e. model was likely just outputting a bias that was close enough but not truly predicting a specific behavior). This may be attributed to the clock bias \"correction\" data being largely a random walk process (with maybe an underlying bias?). While the augmented dickey-fuller test showed results in line with the data not being a random walk process even after testing after subtracting the data's bias from it, other tests demonstrated that it likely is. Other tests included: Fourier analysis (outcome: peaked at 0), data visualization (showed an almost perfect Gaussian distribution - despite tests resulting in a negative outcome for Gaussian classification). This holistic review leads to the conclusion that the data labels are largely noise, and unable to be modeled. \n",
    "\n",
    "This prompts a change in direction for the project: \n",
    "\n",
    "My thesis statement is the following - I am aiming to build low infrastructure ground systems for use on the Moon that leverage novel technology that demonstrated that far GNSS signals can be seen from the Moon. This means that in order to operate a Moon rover, we may be able to leverage these sparse GNSS signals, combined with machine learning, to achieve accurate timing on the Moon. \n",
    "\n",
    "How will this be done: This model will use ephemeris data as inputs and IGS post-processed clock bias products as the labels. Our objective is to model the final clock bias during times when limited inputs are known. \n",
    "\n",
    "This document will demonstrate if this is a possibility with a minimum viable product that uses 1 week of data. The data is expected to be split in a 80/20 fashion for training/validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219ecd5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toy_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
